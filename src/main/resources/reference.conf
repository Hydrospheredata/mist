# spark master
mist.spark.master = "local[*]"

mist.settings.thread-number = 16
mist.settings.single-jvm-mode = false

mist.http.on = false
mist.http.host = "0.0.0.0"
mist.http.port = 2004
# mist.http.router-config-path = ""./configs/router.conf""

mist.mqtt {
  on = false
  host = "localhost"
  port = 1883
  publish-topic = ""
  subscribe-topic = ""
}

mist.kafka {
  on = false
  host = "localhost"
  port = 9092
  publish-topic = ""
  subscribe-topic = ""
}

mist.recovery.on = false

mist.history.on = true
mist.history.type = "Sqlite"
mist.history.filepath = "recovery.db"

mist.workers.runner = "local" # it works with swarm
#mist.workers.host = "localhost"
#mist.workers.port = 80
#mist.workers.shell = """exit 1"""

mist.context-defaults.timeout = 100 days
mist.context-defaults.disposable = false
mist.context-defaults.streaming-duration = 1 seconds

mist.context-defaults.max-parallel-jobs = 20

mist.context-defaults.spark-conf = {
#    spark.default.parallelism = 128
#    spark.driver.memory = "512m"
#    spark.executor.memory = "256m"
#    spark.scheduler.mode = "FAIR"
}

#mist.context.foo.timeout = 100 days
#mist.context.foo.spark-conf = {}

#mist.context.bar.timeout = 1000 second
#mist.context.bar.disposable = true

#mist.context.streaming.timeout = Inf

#mist.context-settings.onstart = ["foo"]

mist.context-defaults.run-options = ""

mist.context-defaults.worker-downtime = Inf

mist.akka {
 actor {
    provider = "akka.cluster.ClusterActorRefProvider"
    debug {
      recieve = off
      autorecieve = off
      lifecycle = off
    }
    warn-about-java-serializer-usage = off
  }

  remote {
    log-remote-lifecycle-events = off
    log-recieved-messages = off
    netty.tcp {
      hostname = "127.0.0.1"
    }
    transport-failure-detector {
      heartbeat-interval = 30s
      acceptable-heartbeat-pause = 5s
    }
  }

  cluster {
    seed-nodes = ["akka.tcp://mist@127.0.0.1:2551"]
    auto-down-unreachable-after = 10s
    log-info = off
  }

  log-dead-letters = 10
  log-dead-letters-during-shutdown = off

  http.server.transparent-head-requests = false
  http.server.idle-timeout = infinite
}

mist.main.akka {
  # Event handlers to register at boot time (Logging$DefaultLogger logs to STDOUT)
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"


  # Log level used by the configured loggers (see "event-handlers") as soon
  # as they have been started; before that, see "stdout-loglevel"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "INFO"

  #logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  # Log level for the very basic logger activated during AkkaApplication startup
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = "INFO"

  log-config-on-start = off

  remote {
    log-remote-lifecycle-events = off
    log-recieved-messages = off
    netty.tcp {
      hostname = "127.0.0.1"
      port = 2551
    }
    transport-failure-detector {
      heartbeat-interval = 30s
      acceptable-heartbeat-pause = 5s
    }
  }

  cluster {
    seed-nodes = ["akka.tcp://mist@127.0.0.1:2551"]
    auto-down-unreachable-after = 10s
    roles = ["master"]
  }
}

mist.worker.akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  loglevel = "INFO"
  stdout-loglevel = "INFO"
  remote.netty.tcp.port = 0

  cluster {
    seed-nodes = ["akka.tcp://mist@127.0.0.1:2551"]
    //auto-down-unreachable-after = 10s
    log-info = off
  }
}

mist.cli.akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  loglevel = "OFF"
  stdout-loglevel = "OFF"
  remote.netty.tcp.port = 0

  cluster {
    log-info = off
  }
}
