mist {

  work-directory = "."
  work-directory = ${?MIST_HOME}

  cluster {
    host = "0.0.0.0"
    port = 2551
  }

  http {
    host = "0.0.0.0"
    port = 2004
    ui = ${mist.work-directory}"/ui"
  }

  mqtt {
    on = false
    host = "localhost"
    port = 1883
    publish-topic = ""
    subscribe-topic = ""
  }

  kafka {
    on = false
    host = "localhost"
    port = 9092
    publish-topic = ""
    subscribe-topic = ""
  }

  log-service {
    host = "localhost"
    port = 2005
    dump_directory = ${mist.work-directory}"/logs"
  }

  db {
    filepath = ${mist.work-directory}"/recovery.db"
  }

  workers {
    runner = "local"
    docker-host = ""
    docker-port = 0
    cmd = ""
    cmdStop = ""
  }

  context-defaults {
    downtime = Inf
    streaming-duration = 1 seconds
    max-parallel-jobs = 20
    precreated = false

    spark-conf {
      #spark.default.parallelism = 128
      #spark.driver.memory = "512m"
      #spark.executor.memory = "256m"
      #spark.scheduler.mode = "FAIR"
    }

    run-options = ""
  }

  context {}

  security {
    enabled = false
    keytab = ""
    principal = ""
    interval = 1 hour
  }
}

writers-blocking-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    fixed-pool-size = 10
  }
  throughput = 1
}

akka {

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  loglevel = "INFO"
  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
  }

  remote {
    netty.tcp {
      hostname = ${mist.cluster.host}
      port = ${mist.cluster.port}
    }
    transport-failure-detector {
      heartbeat-interval = 30s
      acceptable-heartbeat-pause = 5s
    }
  }

  cluster {
    seed-nodes = ["akka.tcp://mist@"${mist.cluster.host}":"${mist.cluster.port}]
    auto-down-unreachable-after = 10s
    log-info = off
    roles = ["master"]
  }

}
